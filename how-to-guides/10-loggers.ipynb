{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ---\n",
    "title: How to use Loggers\n",
    "date: 2021-10-25\n",
    "downloads: true\n",
    "weight: 10\n",
    "summary: \n",
    "tags:\n",
    "  - loggers\n",
    "  - ClearML\n",
    "--- -->\n",
    "\n",
    "# How to use Loggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates the usage of loggers with Ignite. As part of this guide we will be using [ClearML](https://clear.ml/docs/latest/docs/fundamentals/logger/) logger and also hightlight how this code can be easily modified to make use of other loggers. Curious to know about other loggers supported? Check [this](https://pytorch.org/ignite/contrib/handlers.html#loggers) out!\n",
    "\n",
    "### Prerequisities\n",
    "- Refer to the [installation-guide](01-installation.ipynb) to install Ignite (and Pytorch).\n",
    "- To get with ClearML create your account [here](https://app.community.clear.ml/profile), *we will use the commands referred in the setup process (`clearml-init`) in the coming steps, so keep note of the stuff you need to copy!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install model dependencies and ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install -y torchvision  # Needed for model we will train (you could also use pip install torchvision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clearml in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (1.1.2)\n",
      "Requirement already satisfied: pathlib2>=2.3.0 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (2.3.6)\n",
      "Requirement already satisfied: numpy>=1.10 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (1.19.5)\n",
      "Requirement already satisfied: future>=0.16.0 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (0.18.2)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (3.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (1.26.7)\n",
      "Requirement already satisfied: psutil>=3.4.2 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (5.8.0)\n",
      "Requirement already satisfied: pyjwt<2.2.0,>=1.6.4 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (2.1.0)\n",
      "Requirement already satisfied: Pillow>=4.1.1 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (8.4.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (2.26.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (1.16.0)\n",
      "Requirement already satisfied: attrs>=18.0 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (21.2.0)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (6.0)\n",
      "Requirement already satisfied: furl>=2.0.0 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from clearml) (2.1.3)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from furl>=2.0.0->clearml) (1.0.1)\n",
      "Requirement already satisfied: setuptools in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from jsonschema>=2.6.0->clearml) (58.0.4)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from jsonschema>=2.6.0->clearml) (0.18.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from requests>=2.20.0->clearml) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from requests>=2.20.0->clearml) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages (from requests>=2.20.0->clearml) (2.0.7)\n"
     ]
    }
   ],
   "source": [
    "! pip install clearml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML SDK setup process\r\n",
      "Configuration file already exists: /home/anirudh/clearml.conf\r\n",
      "Leaving setup, feel free to edit the configuration file.\r\n"
     ]
    }
   ],
   "source": [
    "! clearml-init # You may want to run this command on your terminal separately and paste what you copied in the step above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Dataset definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we use a convolutional neural network (CNN) to train on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "from ignite.contrib.handlers.clearml_logger import (\n",
    "    ClearMLLogger,\n",
    "    ClearMLSaver,\n",
    "    GradsHistHandler,\n",
    "    GradsScalarHandler,\n",
    "    WeightsHistHandler,\n",
    "    WeightsScalarHandler,\n",
    "    global_step_from_engine,\n",
    ")\n",
    "\n",
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.handlers import Checkpoint\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.utils import setup_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataloaders\n",
    "\n",
    "def get_data_loaders(train_batch_size, val_batch_size):\n",
    "    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        MNIST(download=True, root=\".\", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        MNIST(download=False, root=\".\", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_batch_size, val_batch_size, epochs, lr, momentum):\n",
    "    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
    "    model = Net()\n",
    "    device = \"cpu\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "\n",
    "    model.to(device)  # Move model before creating optimizer\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "    trainer.logger = setup_logger(\"Trainer\")\n",
    "\n",
    "    metrics = {\"accuracy\": Accuracy(), \"loss\": Loss(criterion)}\n",
    "\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "    train_evaluator.logger = setup_logger(\"Train Evaluator\")\n",
    "    validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "    validation_evaluator.logger = setup_logger(\"Val Evaluator\")\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def compute_metrics(engine):\n",
    "        train_evaluator.run(train_loader)\n",
    "        validation_evaluator.run(val_loader)\n",
    "\n",
    "    # To utilize other loggers we need to change the object here\n",
    "    clearml_logger = ClearMLLogger(project_name=\"examples\", task_name=\"ignite\") \n",
    "\n",
    "    # Attach the logger to the trainer to log training loss \n",
    "    clearml_logger.attach_output_handler(\n",
    "        trainer,\n",
    "        event_name=Events.ITERATION_COMPLETED(every=100),\n",
    "        tag=\"training\",\n",
    "        output_transform=lambda loss: {\"batchloss\": loss},\n",
    "    )\n",
    "    \n",
    "    # Attach the logger to log loss and accuracy for both training and validation\n",
    "    for tag, evaluator in [(\"training metrics\", train_evaluator), (\"validation metrics\", validation_evaluator)]:\n",
    "        clearml_logger.attach_output_handler(\n",
    "            evaluator,\n",
    "            event_name=Events.EPOCH_COMPLETED,\n",
    "            tag=tag,\n",
    "            metric_names=[\"loss\", \"accuracy\"],\n",
    "            global_step_transform=global_step_from_engine(trainer),\n",
    "        )\n",
    "\n",
    "    # Attach the logger to the trainer to log optimizer's parameters, e.g. learning rate \n",
    "    clearml_logger.attach_opt_params_handler(\n",
    "        trainer, event_name=Events.ITERATION_COMPLETED(every=100), optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    # Attach the logger to the trainer to log model's weights norm\n",
    "    clearml_logger.attach(\n",
    "        trainer, log_handler=WeightsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100)\n",
    "    )\n",
    "\n",
    "    # Attach the logger to the trainer to log model's weights as a histogram \n",
    "    clearml_logger.attach(trainer, log_handler=WeightsHistHandler(model), event_name=Events.EPOCH_COMPLETED(every=100))\n",
    "\n",
    "    # Attach the logger to the trainer to log model’s gradients as scalars\n",
    "    clearml_logger.attach(\n",
    "        trainer, log_handler=GradsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100)\n",
    "    )\n",
    "\n",
    "    #Attach the logger to the trainer to log model's gradients as a histogram\n",
    "    clearml_logger.attach(trainer, log_handler=GradsHistHandler(model), event_name=Events.EPOCH_COMPLETED(every=100))\n",
    "\n",
    "    handler = Checkpoint(\n",
    "        {\"model\": model},\n",
    "        ClearMLSaver(),\n",
    "        n_saved=1,\n",
    "        score_function=lambda e: e.state.metrics[\"accuracy\"],\n",
    "        score_name=\"val_acc\",\n",
    "        filename_prefix=\"best\",\n",
    "        global_step_transform=global_step_from_engine(trainer),\n",
    "    )\n",
    "    validation_evaluator.add_event_handler(Events.EPOCH_COMPLETED, handler)\n",
    "\n",
    "    # kick everything off\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "\n",
    "    clearml_logger.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "batch_size=64\n",
    "val_batch_size=1000\n",
    "epochs=5 # Number of epoch to train, change this as per your need\n",
    "lr=0.01\n",
    "momentum=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=575b4d9b5c8a47589ac7edb7e5e0bb59\n",
      "ClearML results page: https://app.community.clear.ml/projects/4d6b8ac509bc46da91607e83011248fb/experiments/575b4d9b5c8a47589ac7edb7e5e0bb59/output/log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/miniconda3/envs/ignite/lib/python3.9/site-packages/ignite/contrib/handlers/clearml_logger.py:659: UserWarning: ClearMLSaver created a temporary checkpoints directory: /tmp/ignite_checkpoints_2021_10_25_20_21_50_gkx2f03c\n",
      "  warnings.warn(f\"ClearMLSaver created a temporary checkpoints directory: {dirname}\")\n",
      "2021-10-25 20:21:50,778 Trainer INFO: Engine run starting with max_epochs=5.\n",
      "2021-10-25 20:22:08,993 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:22:18,656 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:10\n",
      "2021-10-25 20:22:18,657 Train Evaluator INFO: Engine run complete. Time taken: 00:00:10\n",
      "2021-10-25 20:22:18,658 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:22:29,442 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:11\n",
      "2021-10-25 20:22:29,443 Val Evaluator INFO: Engine run complete. Time taken: 00:00:11\n",
      "2021-10-25 20:22:29,444 Trainer INFO: Epoch[1] Complete. Time taken: 00:00:39\n",
      "2021-10-25 20:22:46,879 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:22:57,516 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:11\n",
      "2021-10-25 20:22:57,518 Train Evaluator INFO: Engine run complete. Time taken: 00:00:11\n",
      "2021-10-25 20:22:57,519 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:23:12,853 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:15\n",
      "2021-10-25 20:23:12,854 Val Evaluator INFO: Engine run complete. Time taken: 00:00:15\n",
      "2021-10-25 20:23:12,855 Trainer INFO: Epoch[2] Complete. Time taken: 00:00:43\n",
      "2021-10-25 20:23:29,609 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:23:40,388 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:11\n",
      "2021-10-25 20:23:40,390 Train Evaluator INFO: Engine run complete. Time taken: 00:00:11\n",
      "2021-10-25 20:23:40,390 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:23:55,842 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:15\n",
      "2021-10-25 20:23:55,845 Val Evaluator INFO: Engine run complete. Time taken: 00:00:15\n",
      "2021-10-25 20:23:55,845 Trainer INFO: Epoch[3] Complete. Time taken: 00:00:43\n",
      "2021-10-25 20:24:13,223 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:24:23,924 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:11\n",
      "2021-10-25 20:24:23,925 Train Evaluator INFO: Engine run complete. Time taken: 00:00:11\n",
      "2021-10-25 20:24:23,925 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:24:39,658 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:16\n",
      "2021-10-25 20:24:39,661 Val Evaluator INFO: Engine run complete. Time taken: 00:00:16\n",
      "2021-10-25 20:24:39,662 Trainer INFO: Epoch[4] Complete. Time taken: 00:00:44\n",
      "2021-10-25 20:24:57,385 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:25:07,264 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:10\n",
      "2021-10-25 20:25:07,265 Train Evaluator INFO: Engine run complete. Time taken: 00:00:10\n",
      "2021-10-25 20:25:07,267 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-10-25 20:25:22,536 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:15\n",
      "2021-10-25 20:25:22,537 Val Evaluator INFO: Engine run complete. Time taken: 00:00:15\n",
      "2021-10-25 20:25:22,538 Trainer INFO: Epoch[5] Complete. Time taken: 00:00:43\n",
      "2021-10-25 20:25:22,539 Trainer INFO: Engine run complete. Time taken: 00:03:32\n"
     ]
    }
   ],
   "source": [
    "run(batch_size, val_batch_size, epochs, lr, momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you followed along, Congratulations! You can take a look at some of the visualisations from the results page mentioned in you logs above (`ClearML results page`). Here's an example!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Clear ML Dashboard](assets/clearml-dashboard.png)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}